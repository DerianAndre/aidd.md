# ADR: AIDD MCP Ecosystem

> Architecture Decision Record
> **Date**: 2026-02-05
> **Status**: Accepted
> **Deciders**: Project Lead + AI Architect

---

## Context

AIDD is a static, file-based AI development standard (AGENTS.md, rules, skills, workflows, specs, knowledge). To make it actionable, it needs runtime intelligence — guidance, memory, validation, enforcement — delivered through the MCP protocol so any AI client (Claude Code, Cursor, Windsurf) can use it natively.

The key challenge: how to package ~63 tools across 3 domains (brain, memory, tools) while keeping setup simple for most users and flexible for advanced ones.

## Decision

### 1. Engine Default + Optional Split (Approach C)

**Ship one monolithic MCP server (`@aidd.md/mcp-engine`) that bundles all modules**, with the option to run brain/memory/tools as 3 separate servers.

- Default: 1 process, all 63 tools, direct function calls between modules
- Split: 3 processes (`mcp-core`, `mcp-memory`, `mcp-tools`), AI orchestrates cross-server calls

**Why not split-only?**
- Most users want `npx @aidd.md/mcp-engine` — one line in config
- Inter-module calls (e.g., bootstrap reads memory) are free in-process, costly across servers
- Split mode exists for resource isolation and HTTP transport scaling

**Why not monolithic-only?**
- Advanced users may want only the brain (no storage) or only validation (CI pipelines)
- HTTP transport benefits from independent scaling

### 2. npm Distribution

**Distribute as npm packages** (`npx @aidd.md/mcp-engine`), not Docker, not binary, not copied files.

- Standard MCP pattern — every major MCP server ships as npm
- Auto-updates via npx
- No global install required
- Works in CI (`npx @aidd.md/mcp-tools ci --report=json`)

### 3. Hybrid Storage (SQLite + JSON)

**Use SQLite for transient/queryable data, JSON for Git-visible/team-shared data.**

| Data | Backend | Reason |
|------|---------|--------|
| Sessions, observations, analytics | SQLite (.aidd/data.db) | High-write, concurrent, indexed search |
| Decisions, conventions, mistakes | JSON (ai/memory/) | Git-visible, team-shared, diffable |
| Branch context | JSON (.aidd/branches/) | Git-visible per decision |
| Evolution log, drafts | JSON (.aidd/evolution/, .aidd/drafts/) | Audit trail, human-reviewable |
| Search index | SQLite FTS5 | Full-text search performance |

**Why not SQLite-only?**
- Decisions and conventions need to be diffable in PRs
- Team members need to see memory changes in git log
- JSON files in `ai/memory/` are read naturally by AI agents

**Why not JSON-only?**
- Session writes are frequent and concurrent — JSON risks corruption
- FTS5 full-text search is impossible with flat files
- Analytics aggregation queries need SQL

### 4. 3-Layer Search Pattern

**Token-efficient memory retrieval: search → context → get (~10x token savings).**

- `search(query)` → compact index (~50-100 tokens/result)
- `context(anchorId)` → timeline around a result
- `get(ids[])` → full details ONLY for filtered IDs (~500-1000 tokens/result)

**Why not single-call retrieval?**
- Full entries at ~500-1000 tokens each — 10 results = 5000-10000 tokens
- 3-layer lets AI filter at each step, only fetching what's needed
- Proven pattern from claude-mem production system

### 5. 5-Layer Memory Model

**Session → Branch → Lifecycle → Permanent → Evolution.**

| Layer | Scope | Storage | Lifetime |
|-------|-------|---------|----------|
| Session | Single conversation | SQLite | Ephemeral |
| Branch | Git branch | JSON | Branch lifetime |
| Lifecycle | Feature/task (6 AIDD phases) | SQLite | Feature lifetime |
| Permanent | Project | JSON (Git-tracked) | Project lifetime |
| Evolution | Cross-session patterns | JSON (audit trail) | Indefinite |

**Why 5 layers, not fewer?**
- Each layer has a distinct scope and promotion path
- Session data promotes to Branch on session end
- Branch data promotes to Permanent on merge
- Evolution observes all layers for pattern detection

### 6. Module Architecture

**Each domain (core/memory/tools) is a collection of `AiddModule` implementations** with a shared `ModuleContext`.

- Modules register tools/resources/prompts via `McpServer`
- Shared context provides: ContentLoader, ProjectInfo, Config, Logger
- Modules can depend on shared storage (StorageProvider) but not on each other directly
- Module wiring happens in `modules/index.ts` per package

**Why modules, not standalone tools?**
- Related tools share state (e.g., session module manages active session)
- Module lifecycle hooks (`onReady`) enable initialization
- Clean separation of concerns within a single process

### 7. Content Loading (Bundled + Project)

**Bundle AIDD framework files into npm packages, merge with project-level overrides at runtime.**

- Build script copies AGENTS.md, rules, skills, etc. into the package
- At runtime, detect project AIDD files and merge
- Project files override bundled by filename (SSOT: project wins)

**Why bundle at all?**
- Works without cloning aidd.md repo
- `npx @aidd.md/mcp-engine` gives full guidance out of the box
- Project overrides customize without forking

### 8. Pure Validators (Tools Package)

**All 11 validators are pure functions: `(content: string, filePath?) => ValidationResult`.**

- Same code runs in MCP tools and CI mode
- No MCP dependency in validator logic
- CI entrypoint (`mcp-tools ci`) uses validators without MCP transport
- Regex/string parsing only — no heavy dependencies

### 9. Session Threading

**`memorySessionId` + `parentSessionId` for cross-session continuity.**

- Multiple AI conversations can share a memory session ID
- Parent links create a chain of sessions for the same task
- Enables resuming work across disconnections

### 10. Typed Observations with ROI Tracking

**`SessionObservation` with `ObservationType` union + `discoveryTokens` metric.**

- Types: decision, mistake, convention, pattern, preference, insight, tool_outcome, workflow_outcome
- `discoveryTokens`: estimated token cost to discover this info (ROI metric for evolution engine)
- High-discoveryTokens entries are more valuable to preserve

## Consequences

### Positive
- Single `npx` command for full AIDD intelligence
- Works with any MCP-compatible AI client
- Memory persists across sessions and branches
- Evolution engine learns from real usage
- CI integration via same validators
- Token-efficient memory retrieval
- Git-visible decisions and conventions

### Negative
- `better-sqlite3` is an optional native dependency (requires Node.js build tools)
- Monolithic server loads all 63 tools even if user needs only a subset
- Content bundling adds a build step to the release process

### Risks
- SQLite corruption on unclean shutdown — mitigated by WAL mode
- Evolution engine could generate noisy suggestions — mitigated by confidence thresholds (90% auto-apply)
- npm distribution depends on registry availability — mitigated by lockfile pinning

## Alternatives Considered

| Alternative | Why Rejected |
|------------|-------------|
| Docker distribution | Extra dependency, overkill for a dev tool |
| Split-only (no monolith) | Too complex for simple setup |
| Monolith-only (no split) | No CI mode, no granular control |
| PostgreSQL/MongoDB | Massive dependency for a local dev tool |
| JSON-only storage | No FTS5, no transactions, corruption risk |
| SQLite-only storage | Decisions/conventions not Git-visible |
| Single-layer memory | No promotion flow, no cross-session continuity |
| LLM-based pattern detection | Circular dependency, costs tokens |
